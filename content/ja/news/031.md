+++
title = 'Progress in the RISC-V + AI Ecosystem: The llama.cpp Optimization for RVV 1.0 is Complete, Achieving up to a 350% Performance Boost! The Code is Open-Source—Feel Free to Replicate and Explore'
date = 2024-10-26

+++

llama.cpp is a large language model (LLM) inference framework implemented entirely in C/C++, relying heavily on its derivative project, ggml, for tensor operations, which requires high computational performance. 

Recently, **xctan**, an intern at the PLCT Lab, enhanced ggml’s Q4_0_8_8 quantized matrix multiplication operator by adding optimized support for RISC-V Vector 1.0, achieving significant performance improvements.

[Read the full article](https://mp.weixin.qq.com/s/e36oemQkHoSTUpCrcEqFOg)